{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b681a57d-58e4-4bdc-8620-3ec83a0fad42",
   "metadata": {},
   "source": [
    "Due to the handicap that we can only use task's training data and public pre-trained word embeddings, this mostly limits us to pre-transformers era NLP.\n",
    "\n",
    "One of last major similar competitions was 2018 [jigsaw toxicity competition](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/) on kaggle. Some ideas from winners:\n",
    "* [1st place](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/discussion/52557):\n",
    "  * diverse pre-trained embeddings\n",
    "    * \"Given that >90% of a model’s complexity resides in the embedding layer, we decided to focus on the embedding layer rather than the post-embedding layers\"\n",
    "    * \"Since most of the model complexity lay in the pre-trained embeddings, minor architecture changes made very little impact on score. Additional dense layers, gaussian vs. spatial dropout, additional dropout layers at the dense level, attention instead of max pooling, time distributed dense layers, and more barely changed the overall score of the model.\"\n",
    "    * using FastText and Glove embeddings\n",
    "  * model: \"our work-horse was two BiGRU layers feeding into two final Dense layers\"\n",
    "   * translations augmentation - not applicable\n",
    "   * pseudo-labelling, extensive work on cv+stacking - probably only marginally useful here, not worth the effort\n",
    "* [2nd place](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/discussion/52612)\n",
    "  * ensemble of RNN, DPCNN and GBM models\n",
    "  * pre-trained embeddings: FastText, Glove twitter, BPEmb, Word2Vec, LexVec\n",
    "  * translations augmentation - not applicable\n",
    "* [3rd place](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/discussion/52762)\n",
    "  * kitchen sink ensemble of various models from team members\n",
    "  * fasttest and glove twitter vectors; alone and concatenated\n",
    "  * models: GRU, LSTM, GRU+CNN, BiLSTM+GRU\n",
    "  * some char models in the mix instead of usual word/token-based models\n",
    "* 5th place\n",
    "  * concatenated glove, fasttext embeddings with subword information\n",
    "  * main model: 2-level bidirectional gru followed by max pooling and 2 fully-connected layers\n",
    "  * char-level DPCNN and RNN trained over wordparts\n",
    "  * 2 layers of stacking\n",
    "\n",
    "Proposal:\n",
    "  * bidirectional 2-layer LSTM model with fully connected layers at the head\n",
    "  * fasttext and glove embeddings (TODO: others), concatenate multiple embeddings together\n",
    "  * enhance hidden state output (at last timestamp) with its avg/maxpool over time\n",
    "  * ensemble models across different CV folds and seeds, TODO: checkpoint ensembling, ensemble different archs\n",
    "  * minor: 0-pad tokens at the beginning so that last hidden state vector is closer to actual tokens; lower learning rate for embedding layer; TODO: cyclic learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ba2344-83f6-4b58-82c5-18941a9dae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c1b69d-be96-4955-94dd-1fb45eb950bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Split training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76a93ba-0b3f-4fde-be3a-6d1552c8b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_FOLDS = 10\n",
    "CV_SEED = 42\n",
    "CV_PATH_FMT = 'cache/intent/cv{fold}/{split}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae74920-5a90-490a-a516-5a4cb2546779",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json('data/intent/train.json')\n",
    "eval_df = pd.read_json('data/intent/eval.json')\n",
    "test_df = pd.read_json('data/intent/test.json')\n",
    "\n",
    "#TODO: each class should be equally distributed in train and eval fold\n",
    "#Use sklearn.model_selection.StratifiedKFold instead\n",
    "cv = sklearn.model_selection.KFold(\n",
    "    n_splits=CV_FOLDS, shuffle=True, random_state=CV_SEED\n",
    "    )\n",
    "\n",
    "for fold_idx, (train_idx, eval_idx) in enumerate(cv.split(train_df.index)):\n",
    "    for split in ['train', 'eval']:\n",
    "        filename = CV_PATH_FMT.format(fold=fold_idx, split=split)\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        df = train_df.iloc[train_idx if split == 'train' else eval_idx]\n",
    "        df.to_json(filename, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e34413e-4b3c-4df1-92fa-bd86a4424396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 classes, training samples per class: 100..100\n"
     ]
    }
   ],
   "source": [
    "intents = sorted(set(train_df.intent))\n",
    "intent2idx = {s: i for (i, s) in enumerate(intents)}\n",
    "!mkdir -p cache/intent\n",
    "with open('cache/intent/intent2idx.json', 'w') as fp:\n",
    "    json.dump(intent2idx, fp, indent=2)\n",
    "\n",
    "c = train_df.intent.value_counts()\n",
    "print(f'{len(intents)} classes, training samples per class: {c.min()}..{c.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b9803f-7403-4add-bc1a-554cbb309430",
   "metadata": {},
   "source": [
    "Training data is perfectly balanced!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da134cc-d0da-452e-a272-b9fdd0cc804f",
   "metadata": {},
   "source": [
    "### Download and parse pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a34fa3-5ba3-43dc-b331-eaafaba7cc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘crawl-300d-2M.vec.zip’ already there; not retrieving.\n",
      "\n",
      "Archive:  crawl-300d-2M.vec.zip\n",
      "File ‘glove.840B.300d.zip’ already there; not retrieving.\n",
      "\n",
      "Archive:  glove.840B.300d.zip\n"
     ]
    }
   ],
   "source": [
    "# Fasttext: https://fasttext.cc/docs/en/english-vectors.html\n",
    "!cd cache/ && wget -nc https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip  # 1.5G\n",
    "!cd cache/ && unzip -n crawl-300d-2M.vec.zip\n",
    "\n",
    "# Glove: https://nlp.stanford.edu/projects/glove/\n",
    "!cd cache/ && wget -nc https://nlp.stanford.edu/data/glove.840B.300d.zip  # 2.0G\n",
    "!cd cache/ && unzip -n glove.840B.300d.zip\n",
    "\n",
    "# More ideas\n",
    "# https://separius.github.io/awesome-sentence-embedding/#word-embeddings esp. lexvec, bpemb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d1ee8c-ba6d-470e-b7d8-cefbd6aec414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 1999995 x 300d vectors from cache/crawl-300d-2M.vec\n",
      "Parsed 2195875 x 300d vectors from cache/glove.840B.300d.txt\n"
     ]
    }
   ],
   "source": [
    "# parse .txt with fasttext/glove embeddings\n",
    "def parse_embedding_txt(path):\n",
    "    vectors = {}\n",
    "    dim = 0\n",
    "    with open(path) as fp:\n",
    "        for line in fp:\n",
    "            line = line.split()\n",
    "            if len(line) == 2: continue  # fasttext header\n",
    "            if dim == 0:\n",
    "                dim = len(line) - 1\n",
    "            elif dim != len(line) - 1:\n",
    "                continue\n",
    "            vectors[line[0]] = np.array(line[1:], dtype=np.float32)  # will parse strings\n",
    "    print('Parsed %d x %dd vectors from %s' % (len(vectors), dim, path))\n",
    "    return vectors\n",
    "\n",
    "fasttext_vec = parse_embedding_txt('cache/crawl-300d-2M.vec')\n",
    "glove_vec = parse_embedding_txt('cache/glove.840B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7c0666a-5f73-473f-84b5-de9623738cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vec[\"'t\"] = glove_vec[\"n't\"] \n",
    "# alias 't to n't for glove\n",
    "# a quick fix for one fasttext/glove discrepancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6607dc94-190f-465e-b0ef-47d6ca0cf64e",
   "metadata": {},
   "source": [
    "### Generate vocab and embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c943285b-9559-4ddc-acbc-3dc900cf8d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r11922a05/anaconda3/envs/adl-hw1/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from dataset import basic_tokenizer\n",
    "from utils import Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e87ae653-cc1c-4923-8b53-132dcafa7ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size 6320, max len 29\n"
     ]
    }
   ],
   "source": [
    "# for speed, only leave tokens we would ever encounter\n",
    "# alt: use full fasttext+glove vocab; +oov tokens? \n",
    "# use subword vectors for oov?\n",
    "vocab = set()\n",
    "lens = []\n",
    "for text in list(train_df.text) + list(eval_df.text) + list(test_df.text):\n",
    "    tokens = basic_tokenizer(text)\n",
    "    lens += [len(tokens)]\n",
    "    vocab |= set(tokens)\n",
    "vocab = Vocab(list(sorted(vocab)))\n",
    "\n",
    "with open('cache/intent/vocab.pkl', 'wb') as fp:\n",
    "    pickle.dump(vocab, fp)\n",
    "with open('cache/intent/vocab.json', 'w') as fp:\n",
    "    json.dump(vocab.tokens, fp, indent=2)\n",
    "\n",
    "print(f'vocab size {len(vocab.tokens)}, max len {max(lens)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3d237e-6ce2-4ddf-a2ec-33426372b37a",
   "metadata": {},
   "source": [
    "Concatenate both pre-trained embeddings for 600 dims in total, trim to our vocab, initializing OOV tokens randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f75b3d92-14d8-4eec-8be4-cde76a68dae6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6320, 600])\n"
     ]
    }
   ],
   "source": [
    "emb = np.random.normal(\n",
    "    size=(len(vocab.tokens), 600), loc=0.0, scale=0.2\n",
    "    )\n",
    "for token in vocab.tokens:\n",
    "    i = vocab.token_to_id(token)\n",
    "    if token in fasttext_vec:\n",
    "        emb[i, :300] = fasttext_vec[token]\n",
    "    if token in glove_vec:\n",
    "        emb[i, 300:] = glove_vec[token]\n",
    "\n",
    "emb[0, :] = 0.  # zero init the padding token\n",
    "\n",
    "emb = torch.tensor(emb, dtype=torch.float32)\n",
    "torch.save(emb, 'cache/intent/embeddings.pt')\n",
    "print(emb.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('adl-hw1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "075153796ce283a1135a05df4a88665148f05cfe94be538ea710087659147986"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
