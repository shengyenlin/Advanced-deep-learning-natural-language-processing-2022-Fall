{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06593de7-365b-47eb-8c2b-e2300c671c06",
   "metadata": {},
   "source": [
    "* Using same basic architecture as in the first task, but except to do per-token multiclass classification\n",
    "* Calculations in train/eval loops needed to be modified to account for the extra channel and compute joint accuracy, mostly technical\n",
    "* Threw away max/avg pooling layers, just lazy to update them\n",
    "* In preprocessing, discard all tokens without pretrained embedding from the vocabulary - so that at runtime they'd get mapped to `[UNK]` which by itself is a useful signal in this task (many unknown tokens are named entities)\n",
    "* TODO: spatial dropout on embedding layer, also in the first task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ba2344-83f6-4b58-82c5-18941a9dae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c1b69d-be96-4955-94dd-1fb45eb950bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Split training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76a93ba-0b3f-4fde-be3a-6d1552c8b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_FOLDS = 10\n",
    "CV_SEED = 42\n",
    "CV_PATH_FMT = 'cache/slot/cv{fold}/{split}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae74920-5a90-490a-a516-5a4cb2546779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache/slot/cv0/train.json\n",
      "cache/slot/cv0/eval.json\n",
      "cache/slot/cv1/train.json\n",
      "cache/slot/cv1/eval.json\n",
      "cache/slot/cv2/train.json\n",
      "cache/slot/cv2/eval.json\n",
      "cache/slot/cv3/train.json\n",
      "cache/slot/cv3/eval.json\n",
      "cache/slot/cv4/train.json\n",
      "cache/slot/cv4/eval.json\n",
      "cache/slot/cv5/train.json\n",
      "cache/slot/cv5/eval.json\n",
      "cache/slot/cv6/train.json\n",
      "cache/slot/cv6/eval.json\n",
      "cache/slot/cv7/train.json\n",
      "cache/slot/cv7/eval.json\n",
      "cache/slot/cv8/train.json\n",
      "cache/slot/cv8/eval.json\n",
      "cache/slot/cv9/train.json\n",
      "cache/slot/cv9/eval.json\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_json('data/slot/train.json')\n",
    "eval_df = pd.read_json('data/slot/eval.json')\n",
    "test_df = pd.read_json('data/slot/test.json')\n",
    "\n",
    "#TODO: use stratified K-Fold instead\n",
    "cv = sklearn.model_selection.KFold(n_splits=CV_FOLDS, shuffle=True, random_state=CV_SEED)\n",
    "for fold_idx, (train_idx, eval_idx) in enumerate(cv.split(train_df.index)):\n",
    "    for split in ['train', 'eval']:\n",
    "        filename = CV_PATH_FMT.format(fold=fold_idx, split=split)\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        df = train_df.iloc[train_idx if split == 'train' else eval_idx]\n",
    "        df.to_json(filename, orient='records', indent=2)\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e34413e-4b3c-4df1-92fa-bd86a4424396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[PAD]', 'B-date', 'B-first_name', 'B-last_name', 'B-people', 'B-time', 'I-date', 'I-people', 'I-time', 'O']\n"
     ]
    }
   ],
   "source": [
    "intents = set()\n",
    "for tags in train_df.tags:\n",
    "    intents |= set(tags)\n",
    "intents = ['[PAD]'] + list(sorted(intents))\n",
    "\n",
    "intent2idx = {s: i for (i, s) in enumerate(intents)}\n",
    "with open('cache/slot/intent2idx.json', 'w') as fp:\n",
    "    json.dump(intent2idx, fp, indent=2)\n",
    "\n",
    "print(intents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da134cc-d0da-452e-a272-b9fdd0cc804f",
   "metadata": {},
   "source": [
    "### Download and parse pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08b3ab6d-0533-49a1-a72a-0b9dd70d6e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 1999995 x 300d vectors from cache/crawl-300d-2M.vec\n",
      "Parsed 2195875 x 300d vectors from cache/glove.840B.300d.txt\n"
     ]
    }
   ],
   "source": [
    "# reusing data from nb-intent.ipynb\n",
    "\n",
    "# parse .txt with fasttext/glove embeddings\n",
    "def parse_embedding_txt(path):\n",
    "    vectors = {}\n",
    "    dim = 0\n",
    "    with open(path) as fp:\n",
    "        for line in fp:\n",
    "            line = line.split()\n",
    "            if len(line) == 2: continue  # fasttext header\n",
    "            if dim == 0:\n",
    "                dim = len(line) - 1\n",
    "            elif dim != len(line) - 1:\n",
    "                continue\n",
    "            vectors[line[0]] = np.array(line[1:], dtype=np.float32)  # will parse strings\n",
    "    print('Parsed %d x %dd vectors from %s' % (len(vectors), dim, path))\n",
    "    return vectors\n",
    "\n",
    "fasttext_vec = parse_embedding_txt('cache/crawl-300d-2M.vec')\n",
    "glove_vec = parse_embedding_txt('cache/glove.840B.300d.txt')\n",
    "glove_vec[\"'t\"] = glove_vec[\"n't\"]  # alias 't to n't for glove, a quick fix for one fasttext/glove discrepancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6607dc94-190f-465e-b0ef-47d6ca0cf64e",
   "metadata": {},
   "source": [
    "### Generate vocab and embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c943285b-9559-4ddc-acbc-3dc900cf8d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r11922a05/anaconda3/envs/adl-hw1/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from dataset import basic_tokenizer\n",
    "from utils import Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e87ae653-cc1c-4923-8b53-132dcafa7ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full vocab size 4117, max len 35\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "lens = []\n",
    "for df in [train_df, eval_df]:\n",
    "    for tok in df.tokens:\n",
    "        vocab |= set(tok)\n",
    "        lens.append(len(tok))\n",
    "vocab = Vocab(list(sorted(vocab)))\n",
    "print(f'Full vocab size {len(vocab.tokens)}, max len {max(lens)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f75b3d92-14d8-4eec-8be4-cde76a68dae6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 3167 of 4117 tokens\n"
     ]
    }
   ],
   "source": [
    "# task has a large number of tokens for which we don't have any embeddings\n",
    "# missing pretrained embedding for a token alone is likely a useful signal in this task\n",
    "# exclude all such tokens from vocabulary so they'd all get mapped to [UNK]\n",
    "\n",
    "import re\n",
    "\n",
    "def impute(token, pretrained):\n",
    "    # deal with differences in tokenization\n",
    "    token = re.sub(r\"('(s|m|d|t)|)$\", \"\", token) # XXX's i'm i'd can't -> \"\"\n",
    "    token = re.sub(r\"[`~!@#$%^&*(){}\\[\\]\\\":;,.<>/?+â€™`]+\", \"\", token) #punctuations -> \"\"\n",
    "    return pretrained.get(token)\n",
    "\n",
    "imputed_vocab = set()\n",
    "for token in vocab.tokens[2:]:  # exclk PAD, UNK\n",
    "    vec = impute(token, fasttext_vec)\n",
    "    if vec is not None:\n",
    "        imputed_vocab.add(token)\n",
    "    vec = impute(token, glove_vec)\n",
    "    if vec is not None:\n",
    "        imputed_vocab.add(token)\n",
    "\n",
    "imputed_vocab = Vocab(list(sorted(imputed_vocab)))\n",
    "print(f'Found embeddings for {len(imputed_vocab.tokens)} of {len(vocab.tokens)} tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8bed1b71-7f23-4f25-8870-e6cc361be8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = imputed_vocab\n",
    "with open('cache/slot/vocab.pkl', 'wb') as fp:\n",
    "    pickle.dump(vocab, fp)\n",
    "with open('cache/slot/vocab.json', 'w') as fp:\n",
    "    json.dump(vocab.tokens, fp, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "985f7b36-d21a-42dd-948d-7589e2948dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4117, 600])\n"
     ]
    }
   ],
   "source": [
    "emb = np.random.normal(size=(len(vocab.tokens), 600), loc=0.0, scale=0.2)\n",
    "for token in vocab.tokens:\n",
    "    i = vocab.token_to_id(token)\n",
    "    vec = impute(token, fasttext_vec)\n",
    "    if vec is not None:\n",
    "        emb[i, :300] = vec\n",
    "    vec = impute(token, glove_vec)\n",
    "    if vec is not None:\n",
    "        emb[i, 300:] = vec\n",
    "\n",
    "emb[0, :] = 0.  # zero init the padding token\n",
    "\n",
    "emb = torch.tensor(emb, dtype=torch.float32)\n",
    "torch.save(emb, 'cache/slot/embeddings.pt')\n",
    "print(emb.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('adl-hw1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "075153796ce283a1135a05df4a88665148f05cfe94be538ea710087659147986"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
